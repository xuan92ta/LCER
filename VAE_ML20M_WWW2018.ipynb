{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the dataset: [ML-100K/1M](https://grouplens.org/datasets/movielens/), [Alishop](https://jianxinma.github.io/disentangle-recsys.html), or [Epinions](http://www.trustlet.org/downloaded_epinions.html).\n",
    "If dataset is Alishop, data preprocessing can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `DATA_DIR` to the location where dataset sits\n",
    "DATASET = 'ml-100k'\n",
    "DATA_DIR = '/data/jingxuan/dataset/' + DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'ml-100k':\n",
    "    raw_data = pd.read_csv(os.path.join(DATA_DIR, 'u.data'), header=None, names=['userId', 'movieId', 'rating', 'timestamp'], sep='\\t')\n",
    "elif DATASET == 'ml-1m':\n",
    "    raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.dat'), header=None, names=['userId', 'movieId', 'rating', 'timestamp'], sep='::')\n",
    "elif DATASET == 'epinions':\n",
    "    raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings_data.txt'), header=None, names=['userId', 'movieId', 'rating'], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the data (only keep ratings >= 4)\n",
    "raw_data = raw_data[raw_data['rating'] > 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>884182806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>5</td>\n",
       "      <td>891628467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>286</td>\n",
       "      <td>1014</td>\n",
       "      <td>5</td>\n",
       "      <td>879781125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>5</td>\n",
       "      <td>876042340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>122</td>\n",
       "      <td>387</td>\n",
       "      <td>5</td>\n",
       "      <td>879270459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating  timestamp\n",
       "5      298      474       4  884182806\n",
       "7      253      465       5  891628467\n",
       "11     286     1014       5  879781125\n",
       "12     200      222       5  876042340\n",
       "16     122      387       5  879270459"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count  # DataFrame类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        # tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "        tp = tp[tp['movieId'].isin(itemcount[itemcount['size'] >= min_sc]['movidId'])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        # tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "        tp = tp[tp['userId'].isin(usercount[usercount['size'] >= min_uc]['userId'])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 55361 watching events from 938 users and 1447 movies (sparsity: 4.079%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "\n",
    "if DATASET == 'ml-100k':\n",
    "    n_heldout_users = 100\n",
    "elif DATASET == 'ml-1m':\n",
    "    n_heldout_users = 500\n",
    "elif DATASET == 'epinions':\n",
    "    n_heldout_users = 2000\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_dir = os.path.join('pro_sg', DATASET)\n",
    "\n",
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            # print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(pro_dir, 'user_dict.txt'), 'w') as f:\n",
    "    f.write(\"ori_id,new_id\\n\")\n",
    "    for k, v in profile2id.items():\n",
    "        f.write(str(k)+\",\"+str(v)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(pro_dir, 'item_dict.txt'), 'w') as f:\n",
    "    f.write(\"ori_id,new_id\\n\")\n",
    "    for k, v in show2id.items():\n",
    "        f.write(str(k)+\",\"+str(v)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_dir = os.path.join('pro_sg', DATASET)\n",
    "\n",
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))\n",
    "# vad_data_te中部分用户没有test物品"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(738, 1410)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# total_anneal_steps = 7000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)  # bn.argpartition:找到最小的k个元素的索引，其余元素的索引也在但未排序\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)  # 从小到大排序元素，返回索引\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])  # 有0值，说明有些用户没有测试物品\n",
    "    DCG = DCG[IDCG != 0]\n",
    "    IDCG = IDCG[IDCG != 0]\n",
    "    \n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    de = np.minimum(k, X_true_binary.sum(axis=1))  # recall的分母\n",
    "    tmp = tmp[de != 0]\n",
    "    de = de[de != 0]\n",
    "    \n",
    "    recall = tmp / de\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_38130/1965714971.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/769546735.py:19: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/769546735.py:21: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/2845616302.py:91: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/2845616302.py:102: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/2845616302.py:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/2845616302.py:70: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/2845616302.py:78: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/2845616302.py:27: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/2845616302.py:30: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/2845616302.py:33: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/1965714971.py:10: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: log_vae/ml-100k/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n",
      "WARNING:tensorflow:From /tmp/ipykernel_38130/2363550060.py:8: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log_vae/' + DATASET + '/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: chkpt_vae/ml-100k/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = 'chkpt_vae/' + DATASET + '/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 21:38:16.503388: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2022-07-12 21:38:16.529827: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2022-07-12 21:38:16.531888: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5607503a3150 executing computations on platform Host. Devices:\n",
      "2022-07-12 21:38:16.531939: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2022-07-12 21:38:16.534801: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-12 21:38:16.612090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:1b:00.0\n",
      "2022-07-12 21:38:16.612378: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-07-12 21:38:16.613753: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-07-12 21:38:16.615038: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-07-12 21:38:16.615361: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-07-12 21:38:16.616957: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-07-12 21:38:16.618576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-07-12 21:38:16.623143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-12 21:38:16.624562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2022-07-12 21:38:16.624613: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-07-12 21:38:16.762387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-12 21:38:16.762428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2022-07-12 21:38:16.762435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2022-07-12 21:38:16.764472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10321 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5)\n",
      "2022-07-12 21:38:16.766671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56074f83f570 executing computations on platform CUDA. Devices:\n",
      "2022-07-12 21:38:16.766692: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]2022-07-12 21:38:17.511447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "100%|██████████| 200/200 [00:21<00:00,  9.16it/s]\n"
     ]
    }
   ],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf  # 将重构x中的训练数据置为无穷小\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000\n",
    "\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: chkpt_vae/ml-100k/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = 'chkpt_vae/' + DATASET + '/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_dict = {}\n",
    "margin_score_dict = {}\n",
    "\n",
    "def get_topk_items(X_pred, k):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)  # bn.argpartition:找到最小的k个元素的索引，其余元素的索引也在但未排序\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)  # 从小到大排序元素，返回索引\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "\n",
    "    return idx_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/jingxuan/anaconda3/envs/py3_7_tf1_14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from chkpt_vae/ml-100k/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 21:38:40.829754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:1b:00.0\n",
      "2022-07-12 21:38:40.829865: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-07-12 21:38:40.829881: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-07-12 21:38:40.829894: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-07-12 21:38:40.829907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-07-12 21:38:40.829920: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-07-12 21:38:40.829933: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-07-12 21:38:40.829946: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-12 21:38:40.831302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2022-07-12 21:38:40.831352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-12 21:38:40.831358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2022-07-12 21:38:40.831363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2022-07-12 21:38:40.832758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10321 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "n100_list, r20_list, r50_list = [], [], []\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
    "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
    "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
    "\n",
    "        idx_topk = get_topk_items(pred_val, K + 1)\n",
    "        for u in idxlist_test[st_idx:end_idx]:\n",
    "            u_index = idxlist_test[st_idx:end_idx].index(u)\n",
    "            rec_dict[u] = idx_topk[u_index, :-1]\n",
    "            margin_score_dict[u] = pred_val[u_index, idx_topk[u_index, -1]]\n",
    "\n",
    "n100_list = np.concatenate(n100_list)\n",
    "r20_list = np.concatenate(r20_list)\n",
    "r50_list = np.concatenate(r50_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@100=0.46984 (0.01998)\n",
      "Test Recall@20=0.44791 (0.03070)\n",
      "Test Recall@50=0.60192 (0.02738)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储推荐结果\n",
    "with open(\"rec_list_%s.csv\" % DATASET, \"w\") as f:\n",
    "    f.write(\"user_id,margin_score,rec_list\\n\")\n",
    "    for u, items in rec_dict.items():\n",
    "        item_str = '-'.join('%s' % id for id in items)\n",
    "        f.write(\"%d,%f,%s\\n\" % (u, margin_score_dict[u], item_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57a9c87e9a70bfc756f51474cb13bba73a6f014493757c6865d8755804382445"
  },
  "kernelspec": {
   "display_name": "py3_6_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
